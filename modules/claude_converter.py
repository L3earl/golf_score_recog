"""
Claude API ë³€í™˜ ëª¨ë“ˆ

ì˜ë„: ì´ë¯¸ì§€ë¥¼ Claude APIë¡œ ì „ì†¡í•˜ì—¬ ê³¨í”„ ìŠ¤ì½”ì–´ì¹´ë“œ ë°ì´í„° ì¶”ì¶œ
- ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ API í˜¸ì¶œ
- êµ¬ì¡°í™”ëœ JSON ì‘ë‹µì„ DataFrameìœ¼ë¡œ ë³€í™˜
- CSV íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥
"""

import os
import base64
import json
import pandas as pd
from anthropic import Anthropic
from datetime import datetime
from dotenv import load_dotenv
import logging
import sys
import cv2
import numpy as np
import urllib.request
import time
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from modules.utils import get_image_files, ensure_directory
from config import (
    DEFAULT_CLAUDE_MODEL, 
    RAW_IMG_FOLDER, 
    RAW_IMG_UPSCALE_FOLDER,
    RESULT_CONVERT_NUM_FOLDER, 
    CSV_ENCODING,
    IMAGE_EXTENSIONS,
    CLAUDE_GOLF_PROMPT,
    CLAUDE_EXTRACT_SCORECARD_TOOL,
    CLAUDE_MAX_TOKENS,
    MODELS_FOLDER,
    EDSR_MODEL_URL,
    UPSCALE_MAX_SIZE,
    CLAUDE_MAX_RETRIES,
    IMAGE_MAX_SIZE_MB,
    JPEG_INITIAL_QUALITY,
    JPEG_MIN_QUALITY
)

logger = logging.getLogger(__name__)

class ClaudeConverter:
    """Claude API ë³€í™˜ í´ë˜ìŠ¤
    
    ì˜ë„: ì´ë¯¸ì§€ë¥¼ Claude APIë¡œ ì „ì†¡í•˜ì—¬ ê³¨í”„ ìŠ¤ì½”ì–´ì¹´ë“œ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì¶”ì¶œ
    """
    
    def __init__(self, model_name=None):
        """Claude ë³€í™˜ê¸° ì´ˆê¸°í™”
        
        ì˜ë„: ì„¤ì •ê°’ì„ ë¡œë“œí•˜ê³  Claude API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±
        
        Args:
            model_name: ì‚¬ìš©í•  Claude ëª¨ë¸ëª… (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        """
        self.model_name = model_name or DEFAULT_CLAUDE_MODEL
        self.prompt = CLAUDE_GOLF_PROMPT
        self.input_folder = RAW_IMG_FOLDER
        self.upscale_folder = RAW_IMG_UPSCALE_FOLDER  # ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ì €ì¥ í´ë”
        self.output_folder = RESULT_CONVERT_NUM_FOLDER
        self.csv_encoding = CSV_ENCODING
        self.image_extensions = IMAGE_EXTENSIONS
        self.models_folder = MODELS_FOLDER

        # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
        load_dotenv()

        # Claude API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.client = self._get_claude_client()
        
        # Super Resolution ëª¨ë¸ ë¡œë“œ
        self.superres_model = self._load_superres_model()
        logger.debug(f"ClaudeConverter ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model_name})")
    
    def _get_claude_client(self):
        """Claude API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        
        ì˜ë„: í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ Claude í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        
        Returns:
            Anthropic í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
        
        Raises:
            ValueError: API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°
        """
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key:
            logger.error("ANTHROPIC_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            raise ValueError("âŒ ANTHROPIC_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        logger.info(f"Claude API í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ! (ëª¨ë¸: {self.model_name})")
        return Anthropic(api_key=api_key)
    
    def _download_model_file(self):
        """EDSR ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        
        ì˜ë„: EDSR_x4.pb ëª¨ë¸ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
        
        Returns:
            ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            # models í´ë” ìƒì„±
            os.makedirs(self.models_folder, exist_ok=True)
            
            model_path = os.path.join(self.models_folder, "EDSR_x4.pb")
            
            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
            if os.path.exists(model_path):
                logger.info(f"ëª¨ë¸ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {model_path}")
                return model_path
            
            # ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            logger.info("EDSR ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            urllib.request.urlretrieve(EDSR_MODEL_URL, model_path)
            logger.info(f"ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {model_path}")
            
            return model_path
            
        except Exception as e:
            logger.warning(f"ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def _load_superres_model(self):
        """OpenCV DNN Super Resolution ëª¨ë¸ ë¡œë“œ
        
        ì˜ë„: cv2.dnn_superresë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠˆí¼ í•´ìƒë„ ëª¨ë¸ ë¡œë“œ
        
        Returns:
            ìŠˆí¼ í•´ìƒë„ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            # ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            model_path = self._download_model_file()
            if not model_path:
                logger.warning("ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ìŠˆí¼ í•´ìƒë„ ëª¨ë¸ ìƒì„±
            sr = cv2.dnn_superres.DnnSuperResImpl_create()
            sr.readModel(model_path)
            sr.setModel("edsr", 4)  # EDSR ëª¨ë¸, 4ë°° ì—…ìŠ¤ì¼€ì¼ë§
            
            logger.info("OpenCV DNN Super Resolution ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            return sr
            
        except Exception as e:
            logger.warning(f"ìŠˆí¼ í•´ìƒë„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.info("ìŠˆí¼ í•´ìƒë„ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
            return None

    def _resize_image_if_needed(self, image, max_size=None):
        """ì´ë¯¸ì§€ê°€ ì§€ì •ëœ í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ë©´ ë¦¬ì‚¬ì´ì¦ˆ
        
        ì˜ë„: ì´ë¯¸ì§€ì˜ ê°€ë¡œì„¸ë¡œê°€ ì§€ì •ëœ í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ë©´ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
        
        Args:
            image: OpenCV ì´ë¯¸ì§€ ë°°ì—´
            max_size: ìµœëŒ€ í¬ê¸° (ê¸°ë³¸ê°’: UPSCALE_MAX_SIZE)
        
        Returns:
            ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ë°°ì—´
        """
        if max_size is None:
            max_size = UPSCALE_MAX_SIZE
            
        height, width = image.shape[:2]
        if max(height, width) > max_size:
            # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ
            if height > width:
                new_height = max_size
                new_width = int(width * max_size / height)
            else:
                new_width = max_size
                new_height = int(height * max_size / width)
            
            image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            logger.info(f"ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ: {width}x{height} â†’ {new_width}x{new_height}")
        
        return image

    def _upscale_image(self, image_path):
        """ì´ë¯¸ì§€ë¥¼ OpenCV DNN Super Resolutionìœ¼ë¡œ ì—…ìŠ¤ì¼€ì¼ë§í•˜ê³  íŒŒì¼ë¡œ ì €ì¥
        
        ì˜ë„: ì…ë ¥ ì´ë¯¸ì§€ë¥¼ cv2.dnn_superresë¡œ 4ë°° ì—…ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ì„ ëª…í•˜ê²Œ ë§Œë“¤ê³  íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            image_path: ì—…ìŠ¤ì¼€ì¼ë§í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ë°°ì—´ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img = cv2.imread(image_path, cv2.IMREAD_COLOR)
            if img is None:
                logger.warning(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
                return None
            
            # ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ìƒì„±
            if self.superres_model is not None:
                output = self.superres_model.upsample(img)
                logger.info(f"OpenCV DNN Super Resolution ì—…ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: {image_path}")
            else:
                # ìŠˆí¼ í•´ìƒë„ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ì—…ìŠ¤ì¼€ì¼ë§
                height, width = img.shape[:2]
                output = cv2.resize(img, (width * 4, height * 4), interpolation=cv2.INTER_CUBIC)
                logger.info(f"ê°„ë‹¨í•œ ì—…ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ: {image_path}")
            
            # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
            output = self._resize_image_if_needed(output)
            
            # ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            image_name = os.path.basename(image_path)
            image_name_no_ext = os.path.splitext(image_name)[0]
            upscale_output_path = os.path.join(self.upscale_folder, f"{image_name_no_ext}.png")
            
            # ì—…ìŠ¤ì¼€ì¼ë§ í´ë” ìƒì„±
            ensure_directory(self.upscale_folder)
            
            # PNGë¡œ ì €ì¥ (í’ˆì§ˆ ì†ì‹¤ ì—†ìŒ)
            success = cv2.imwrite(upscale_output_path, output)
            if success:
                logger.info(f"ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {upscale_output_path}")
            else:
                logger.warning(f"ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {upscale_output_path}")
            
            return output
                
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ ({image_path}): {e}")
            return None

    def _get_media_type(self, image_path):
        """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì ì ˆí•œ media_type ë°˜í™˜
        
        ì˜ë„: íŒŒì¼ í™•ì¥ìì— ë”°ë¼ Claude APIê°€ ìš”êµ¬í•˜ëŠ” ì˜¬ë°”ë¥¸ media_type ì„¤ì •
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ì ì ˆí•œ media_type ë¬¸ìì—´
        """
        ext = os.path.splitext(image_path)[1].lower()
        media_type_map = {
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.bmp': 'image/bmp',
            '.tiff': 'image/tiff',
            '.tif': 'image/tiff'
        }
        return media_type_map.get(ext, 'image/png')  # ê¸°ë³¸ê°’ì€ png

    def _compress_image_for_api(self, image, max_size_mb=None):
        """API ì „ì†¡ì„ ìœ„í•´ ì´ë¯¸ì§€ ì••ì¶•
        
        ì˜ë„: ì´ë¯¸ì§€ íŒŒì¼ í¬ê¸°ê°€ ì œí•œì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì••ì¶•
        
        Args:
            image: OpenCV ì´ë¯¸ì§€ ë°°ì—´
            max_size_mb: ìµœëŒ€ í¬ê¸° (MB, ê¸°ë³¸ê°’: IMAGE_MAX_SIZE_MB)
        
        Returns:
            ì••ì¶•ëœ ì´ë¯¸ì§€ ë°°ì—´
        """
        if max_size_mb is None:
            max_size_mb = IMAGE_MAX_SIZE_MB
            
        # PNGë¡œ ì¸ì½”ë”©í•˜ì—¬ í¬ê¸° í™•ì¸
        _, buffer = cv2.imencode('.png', image)
        size_mb = len(buffer) / (1024 * 1024)
        
        if size_mb <= max_size_mb:
            return image
        
        logger.info(f"ì´ë¯¸ì§€ í¬ê¸°: {size_mb:.2f}MB, ì••ì¶• í•„ìš”")
        
        # JPEGë¡œ ë³€í™˜í•˜ì—¬ ì••ì¶•
        quality = JPEG_INITIAL_QUALITY
        while quality > JPEG_MIN_QUALITY:
            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]
            _, buffer = cv2.imencode('.jpg', image, encode_param)
            size_mb = len(buffer) / (1024 * 1024)
            
            if size_mb <= max_size_mb:
                logger.info(f"JPEG ì••ì¶• ì™„ë£Œ: {size_mb:.2f}MB (í’ˆì§ˆ: {quality})")
                return image
            
            quality -= 10
        
        # ì—¬ì „íˆ í¬ë©´ ì´ë¯¸ì§€ í¬ê¸° ìì²´ë¥¼ ì¤„ì´ê¸°
        logger.warning("í’ˆì§ˆ ì••ì¶•ìœ¼ë¡œë„ í¬ê¸° ì´ˆê³¼, ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ")
        height, width = image.shape[:2]
        scale_factor = 0.8
        while scale_factor > 0.3:
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)
            resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            _, buffer = cv2.imencode('.jpg', resized, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
            size_mb = len(buffer) / (1024 * 1024)
            
            if size_mb <= max_size_mb:
                logger.info(f"ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ ì™„ë£Œ: {size_mb:.2f}MB ({new_width}x{new_height})")
                return resized
            
            scale_factor -= 0.1
        
        logger.error("ì´ë¯¸ì§€ ì••ì¶• ì‹¤íŒ¨")
        return image
    
    def _process_image_with_retry(self, image_path, upscaled_img=None, max_retries=None):
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ Claude API ì´ë¯¸ì§€ ì²˜ë¦¬
        
        ì˜ë„: API í˜¸ì¶œ ì‹¤íŒ¨ì‹œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ê¹Œì§€ ì¬ì‹œë„
        
        Args:
            image_path: ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            upscaled_img: ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ë°°ì—´ (ì„ íƒì‚¬í•­)
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: CLAUDE_MAX_RETRIES)
        
        Returns:
            Claude API ì‘ë‹µ ë©”ì‹œì§€ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        if max_retries is None:
            max_retries = CLAUDE_MAX_RETRIES
            
        for attempt in range(max_retries):
            try:
                response = self._process_image(image_path, upscaled_img)
                if response is not None:
                    if attempt > 0:
                        logger.info(f"ì¬ì‹œë„ ì„±ê³µ (ì‹œë„ {attempt + 1})")
                    return response
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„: 2ì´ˆ, 4ì´ˆ, 8ì´ˆ
                    logger.warning(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨, {wait_time}ì´ˆ í›„ ì¬ì‹œë„ ì¤‘... ({e})")
                    time.sleep(wait_time)
                else:
                    logger.error(f"ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {e}")
        
        return None

    def _process_image(self, image_path, upscaled_img=None):
        """Claude APIë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬
        
        ì˜ë„: ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ Claude APIì— ì „ì†¡í•˜ê³  êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
        
        Args:
            image_path: ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            upscaled_img: ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ë°°ì—´ (ì„ íƒì‚¬í•­)
        
        Returns:
            Claude API ì‘ë‹µ ë©”ì‹œì§€ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            if upscaled_img is not None:
                # ì´ë¯¸ì§€ ì••ì¶• ì ìš©
                compressed_img = self._compress_image_for_api(upscaled_img)
                
                # ì••ì¶•ëœ ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”© (PNGë³´ë‹¤ ì‘ìŒ)
                _, buffer = cv2.imencode('.jpg', compressed_img, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
                image_data = base64.b64encode(buffer).decode('utf-8')
                media_type = 'image/jpeg'
                logger.info(f"ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ì‚¬ìš©: {image_path}")
            else:
                # ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                with open(image_path, "rb") as image_file:
                    image_data = base64.b64encode(image_file.read()).decode('utf-8')
                media_type = self._get_media_type(image_path)
                logger.info(f"ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©: {image_path}")
            
            # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ì™€ ìœ ì—°í•œ ìŠ¤í‚¤ë§ˆ ì‚¬ìš©
            tools = [CLAUDE_EXTRACT_SCORECARD_TOOL]

            message = self.client.messages.create(
                model=self.model_name,
                max_tokens=CLAUDE_MAX_TOKENS,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "image", "source": {"type": "base64", "media_type": media_type, "data": image_data}},
                            {"type": "text", "text": self.prompt}
                        ]
                    }
                ],
                tools=tools
                # tool_choice ì œê±° - ëª¨ë¸ì´ ììœ¨ì ìœ¼ë¡œ íŒë‹¨
            )

            logger.debug(f"Claude API í˜¸ì¶œ ì„±ê³µ: {image_path} (media_type: {media_type})")
            return message
        except Exception as e:
            logger.error(f"Claude API í˜¸ì¶œ ì‹¤íŒ¨ ({image_path}): {e}")
            return None
    
    def _parse_json_to_dataframe(self, message_response, image_name):
        """Claude API ì‘ë‹µì„ DataFrameìœ¼ë¡œ ë³€í™˜
        
        ì˜ë„: Claude APIì˜ tool_use ì‘ë‹µì—ì„œ JSON ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ DataFrame ìƒì„±
        
        Args:
            message_response: Claude API ì‘ë‹µ ë©”ì‹œì§€
            image_name: ì´ë¯¸ì§€ íŒŒì¼ëª…
        
        Returns:
            ë³€í™˜ëœ DataFrame ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            # tool_use ì‘ë‹µì¸ì§€ í™•ì¸
            if message_response.stop_reason != "tool_use":
                logger.warning(f"'{image_name}'ì—ì„œ tool_use ì‘ë‹µì´ ì•„ë‹™ë‹ˆë‹¤. (Stop Reason: {message_response.stop_reason})")
                return None
            
            # tool_use ë¸”ë¡ ì°¾ê¸°
            tool_use_block = next(
                (block for block in message_response.content if block.type == "tool_use"),
                None
            )
            
            if not tool_use_block:
                logger.warning(f"'{image_name}'ì—ì„œ tool_use ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # JSON ë°ì´í„° ì¶”ì¶œ
            json_data = tool_use_block.input
            
            # ë””ë²„ê¹…: Claudeì—ì„œ ë°›ì€ JSON ë°ì´í„° ì¶œë ¥
            print(f"  ğŸ” Claude JSON ì‘ë‹µ:")
            print(f"  {json.dumps(json_data, indent=2, ensure_ascii=False)}")
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if "par" not in json_data or "players" not in json_data:
                logger.warning(f"'{image_name}'ì—ì„œ í•„ìˆ˜ í•„ë“œ 'par' ë˜ëŠ” 'players'ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return None
            
            par_data = json_data["par"]
            players_data = json_data["players"]
            
            # par ë°°ì—´ ê¸¸ì´ ê²€ì¦ (18ê°œ ì´ìƒ)
            min_expected_length = 18
            actual_length = len(par_data)
            
            if actual_length < min_expected_length:
                logger.warning(f"par ë°°ì—´ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ: {min_expected_length}, ì‹¤ì œ: {actual_length}")
                return None
            
            # í”Œë ˆì´ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
            if not players_data:
                logger.warning(f"'{image_name}'ì—ì„œ í”Œë ˆì´ì–´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ëª¨ë“  í”Œë ˆì´ì–´ì˜ ìŠ¤ì½”ì–´ ë°°ì—´ ê¸¸ì´ ê²€ì¦
            for i, player in enumerate(players_data):
                if "scores" not in player:
                    logger.warning(f"í”Œë ˆì´ì–´ {i+1}ì—ì„œ 'scores' í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    return None
                
                scores = player["scores"]
                if len(scores) != actual_length:
                    player_name = player.get("name", f"Player {i+1}")
                    logger.warning(f"'{player_name}' ìŠ¤ì½”ì–´ ë°°ì—´ ê¸¸ì´ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆìƒ: {actual_length}, ì‹¤ì œ: {len(scores)}")
                    return None
            
            print(f"  âœ… ëª¨ë“  ë°°ì—´ ê¸¸ì´ ì¼ì¹˜: {actual_length}ê°œ í™€, {len(players_data)}ëª… í”Œë ˆì´ì–´")
            
            # DataFrame ìƒì„±
            data = {
                "í™€": list(range(1, actual_length + 1)),
                "PAR": par_data
            }
            
            # ê° í”Œë ˆì´ì–´ì˜ ìŠ¤ì½”ì–´ ì¶”ê°€
            for player in players_data:
                player_name = player.get("name", "Unknown Player")
                data[player_name] = player["scores"]
            
            df = pd.DataFrame(data)
            
            # ë¹ˆ DataFrame ì²´í¬
            if df.empty:
                logger.warning(f"'{image_name}'ì—ì„œ ë¹ˆ DataFrameì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤")
                return None
            
            return df
            
        except Exception as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜ ({image_name}): {e}")
            logger.debug(f"API Raw Response - Stop Reason: {message_response.stop_reason}")
            return None
    
    def _save_dataframe_to_csv(self, df, output_file):
        """DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥
        
        ì˜ë„: ì²˜ë¦¬ëœ DataFrameì„ ì§€ì •ëœ ê²½ë¡œì— CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            df: ì €ì¥í•  DataFrame
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        ensure_directory(os.path.dirname(output_file))
        df.to_csv(output_file, index=False, header=True, encoding=self.csv_encoding)

    def _convert_to_csv_format(self, df, image_name):
        """DataFrameì„ CSV ì €ì¥ìš© í˜•íƒœë¡œ ë³€í™˜
        
        ì˜ë„: case1_02.csv í˜•íƒœë¡œ ë³€í™˜ (Transpose + total1, total2, sum ì¶”ê°€)
        ì¶”ê°€ë¡œ ì ˆëŒ€ì ìˆ˜ë¡œ í‘œì‹œëœ í”Œë ˆì´ì–´ ë°ì´í„°ë¥¼ ìƒëŒ€ì ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” í›„ì²˜ë¦¬ ì ìš©
        
        í›„ì²˜ë¦¬ ë¡œì§:
        1. ê° í”Œë ˆì´ì–´ì˜ diff_sum ê³„ì‚° (|ìŠ¤ì½”ì–´ - PAR|ì˜ í•©)
        2. diff_sum < 36ì¸ í”Œë ˆì´ì–´ëŠ” ì ˆëŒ€ì ìˆ˜ë¡œ íŒë‹¨í•˜ì—¬ ìƒëŒ€ì ìˆ˜ë¡œ ë³€í™˜
        3. ëª¨ë“  í”Œë ˆì´ì–´ì˜ total1, total2, sumì„ ì ˆëŒ€ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì¬ê³„ì‚°
        
        Args:
            df: ì›ë³¸ DataFrame (í™€, PAR, í”Œë ˆì´ì–´ë“¤)
            image_name: ì´ë¯¸ì§€ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        
        Returns:
            ë³€í™˜ëœ DataFrame ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        try:
            # PAR í–‰ê³¼ í”Œë ˆì´ì–´ í–‰ë“¤ë§Œ ì¶”ì¶œ
            par_row = df['PAR'].values
            player_rows = []
            player_names = []
            
            # PAR ë°ì´í„° ê¸¸ì´ í™•ì¸ (18í™€ì´ì–´ì•¼ í•¨)
            if len(par_row) != 18:
                logger.warning(f"'{image_name}'ì—ì„œ PAR ë°ì´í„° ê¸¸ì´ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆìƒ: 18, ì‹¤ì œ: {len(par_row)}")
                return None
            
            # í”Œë ˆì´ì–´ ì»¬ëŸ¼ë“¤ ì¶”ì¶œ (PAR ì œì™¸)
            for col in df.columns:
                if col not in ['í™€', 'PAR']:
                    player_rows.append(df[col].values)
                    player_names.append(col)
            
            if not player_rows:
                logger.warning(f"'{image_name}'ì—ì„œ í”Œë ˆì´ì–´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # í›„ì²˜ë¦¬: ì ˆëŒ€ì ìˆ˜ â†’ ìƒëŒ€ì ìˆ˜ ë³€í™˜
            processed_player_rows = []
            for i, (player_name, player_scores) in enumerate(zip(player_names, player_rows)):
                # 1ë‹¨ê³„: 0 ì´í•˜ ìˆ«ì í™•ì¸
                has_zero_or_negative = any(score <= 0 for score in player_scores)
                
                # 2ë‹¨ê³„: í‰ê· ê°’ ê¸°ë°˜ íŒë‹¨
                par_average = sum(par_row) / len(par_row)  # PAR í‰ê· 
                player_average = sum(player_scores) / len(player_scores)  # í”Œë ˆì´ì–´ í‰ê· 
                threshold = par_average - 0.5  # ì„ê³„ê°’
                
                logger.info(f"í”Œë ˆì´ì–´ '{player_name}' PAR í‰ê· : {par_average:.2f}, í”Œë ˆì´ì–´ í‰ê· : {player_average:.2f}, ì„ê³„ê°’: {threshold:.2f}")
                
                if has_zero_or_negative:
                    # 0 ì´í•˜ ìˆ«ìê°€ ìˆìœ¼ë©´ ìƒëŒ€ì ìˆ˜ë¡œ íŒë‹¨ (ë³€í™˜ ì•ˆí•¨)
                    logger.info(f"í”Œë ˆì´ì–´ '{player_name}' ìƒëŒ€ì ìˆ˜ë¡œ íŒë‹¨ (0 ì´í•˜ ìˆ«ì í¬í•¨)")
                    processed_player_rows.append(player_scores)
                elif player_average > threshold:
                    # í”Œë ˆì´ì–´ í‰ê·  > (PAR í‰ê·  - 0.5)ì´ë©´ ì ˆëŒ€ì ìˆ˜ë¡œ íŒë‹¨í•˜ì—¬ ìƒëŒ€ì ìˆ˜ë¡œ ë³€í™˜
                    logger.info(f"í”Œë ˆì´ì–´ '{player_name}' ì ˆëŒ€ì ìˆ˜ â†’ ìƒëŒ€ì ìˆ˜ ë³€í™˜ (í”Œë ˆì´ì–´ í‰ê· : {player_average:.2f} > ì„ê³„ê°’: {threshold:.2f})")
                    relative_scores = [score - par for score, par in zip(player_scores, par_row)]
                    processed_player_rows.append(relative_scores)
                else:
                    # ê·¸ ì™¸ëŠ” ìƒëŒ€ì ìˆ˜ë¡œ íŒë‹¨í•˜ì—¬ ë³€í™˜ ì•ˆí•¨
                    logger.info(f"í”Œë ˆì´ì–´ '{player_name}' ìƒëŒ€ì ìˆ˜ ìœ ì§€ (í”Œë ˆì´ì–´ í‰ê· : {player_average:.2f} <= ì„ê³„ê°’: {threshold:.2f})")
                    processed_player_rows.append(player_scores)
            
            # ìƒˆë¡œìš´ DataFrame ìƒì„± (Transpose)
            data = {}
            
            # í™€ë³„ ì»¬ëŸ¼ ì¶”ê°€ (1í™€, 2í™€, ..., 18í™€)
            for i in range(len(par_row)):
                data[f"{i+1}í™€"] = [par_row[i]] + [player[i] for player in processed_player_rows]
            
            # total1, total2, sum ì´ˆê¸°í™”
            data['total1'] = []
            data['total2'] = []
            data['sum'] = []
            
            # PAR í–‰ì˜ total1, total2, sum ê³„ì‚°
            par_total1 = sum(par_row[:9])
            par_total2 = sum(par_row[9:18])
            par_sum = par_total1 + par_total2
            
            data['total1'].append(par_total1)
            data['total2'].append(par_total2)
            data['sum'].append(par_sum)
            
            # 3ë‹¨ê³„: ê° í”Œë ˆì´ì–´ì˜ total1, total2, sum ì¬ê³„ì‚° (ì ˆëŒ€ì ìˆ˜ ê¸°ì¤€)
            for player_scores in processed_player_rows:
                # í”Œë ˆì´ì–´ì˜ 1~9í™€, 10~18í™€ í•©ê³„ ê³„ì‚°
                player_total1 = sum(player_scores[:9])   # ì „ë°˜ 9í™€ í•©ê³„
                player_total2 = sum(player_scores[9:18]) # í›„ë°˜ 9í™€ í•©ê³„
                
                # ì ˆëŒ€ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ total ê³„ì‚°
                total1 = par_total1 + player_total1  # PARì˜ total1 + í”Œë ˆì´ì–´ì˜ 1~9í™€ í•©ê³„
                total2 = par_total2 + player_total2  # PARì˜ total2 + í”Œë ˆì´ì–´ì˜ 10~18í™€ í•©ê³„
                total_sum = total1 + total2
                
                data['total1'].append(total1)
                data['total2'].append(total2)
                data['sum'].append(total_sum)
                
                logger.info(f"í”Œë ˆì´ì–´ total ì¬ê³„ì‚°: total1={total1}, total2={total2}, sum={total_sum}")
            
            result_df = pd.DataFrame(data)
            
            return result_df
            
        except Exception as e:
            logger.error(f"CSV ë³€í™˜ ì˜¤ë¥˜ ({image_name}): {e}")
            return None
    
    def convert_specific_images(self, image_names):
        """íŠ¹ì • ì´ë¯¸ì§€ë“¤ë§Œ Claude APIë¡œ ë³€í™˜
        
        ì˜ë„: ì§€ì •ëœ ì´ë¯¸ì§€ íŒŒì¼ëª…ë“¤ì„ Claude APIë¡œ ì²˜ë¦¬í•˜ì—¬ ê°œë³„ CSV íŒŒì¼ ìƒì„±
        íë¦„: data/raw_img â†’ data/raw_img_upscale â†’ Claude API â†’ data/result_convert/case99
        
        Args:
            image_names: ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ (í™•ì¥ì ì œì™¸)
        
        Returns:
            ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        logger.info("Claude API ë³€í™˜ ì‹œì‘...")
        logger.info(f"ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"ì…ë ¥ í´ë”: {self.input_folder}")
        logger.info(f"ì—…ìŠ¤ì¼€ì¼ë§ ì €ì¥ í´ë”: {self.upscale_folder}")
        logger.info(f"ì¶œë ¥ í´ë”: {self.output_folder}")
        logger.info(f"ëª¨ë¸: {self.model_name}")
        logger.info("-" * 60)
        
        try:
            # íŠ¹ì • ì´ë¯¸ì§€ íŒŒì¼ë“¤ë§Œ ì²˜ë¦¬
            image_files = []
            for image_name in image_names:
                # í™•ì¥ì ì¶”ê°€
                for ext in self.image_extensions:
                    image_path = os.path.join(self.input_folder, f"{image_name}{ext}")
                    if os.path.exists(image_path):
                        image_files.append(image_path)
                        break
            
            if not image_files:
                logger.error(f"ì§€ì •ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_names}")
                return False
            
            logger.info(f"ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜: {len(image_files)}")
            
            # ì²˜ë¦¬ ê²°ê³¼ í†µê³„
            processed_count = 0
            failed_count = 0
            
            # ë¨¼ì € ëª¨ë“  ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ ì§„í–‰
            logger.info("ëª¨ë“  ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ ì‹œì‘...")
            upscaled_images = {}
            
            for i, image_path in enumerate(image_files, 1):
                image_name = os.path.basename(image_path)
                logger.info(f"[{i}/{len(image_files)}] ì—…ìŠ¤ì¼€ì¼ë§ ì¤‘: {image_name}")
                
                upscaled_img = self._upscale_image(image_path)
                if upscaled_img is not None:
                    upscaled_images[image_path] = upscaled_img
                    logger.info(f"ì—…ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ!")
                else:
                    logger.warning(f"ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨")
            
            logger.info(f"ëª¨ë“  ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ! ({len(upscaled_images)}ê°œ ì„±ê³µ)")
            
            # case99 ì „ìš© ì¶œë ¥ í´ë” ì„¤ì •
            case99_output_folder = os.path.join(self.output_folder, "case99")
            ensure_directory(case99_output_folder)
            
            # ê° ì´ë¯¸ì§€ ì²˜ë¦¬
            for i, image_path in enumerate(image_files, 1):
                image_name = os.path.basename(image_path)
                image_name_no_ext = os.path.splitext(image_name)[0]
                logger.info(f"[{i}/{len(image_files)}] API ì²˜ë¦¬ ì¤‘: {image_name}")
                
                if image_path not in upscaled_images:
                    logger.warning(f"ì—…ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨ë¡œ ê±´ë„ˆë›°ê¸°: {image_name}")
                    failed_count += 1
                    continue
                
                try:
                    # Claude API í˜¸ì¶œ
                    response = self._process_image_with_retry(image_path, upscaled_images[image_path])
                    
                    if response is None:
                        failed_count += 1
                        logger.warning(f"ì‹¤íŒ¨: Claude API í˜¸ì¶œ ì‹¤íŒ¨")
                        continue
                    
                    # JSONì„ DataFrameìœ¼ë¡œ ë³€í™˜
                    result_df = self._parse_json_to_dataframe(response, image_name)
                    
                    if result_df is not None:
                        logger.info(f"ì„±ê³µ: {result_df.shape[0]}ê°œ í™€, {result_df.shape[1]-2}ëª… í”Œë ˆì´ì–´")
                        
                        # CSV í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                        csv_df = self._convert_to_csv_format(result_df, image_name_no_ext)
                        
                        if csv_df is not None:
                            # case99 í´ë”ì— ê°œë³„ CSV íŒŒì¼ë¡œ ì €ì¥
                            output_file = os.path.join(case99_output_folder, f"{image_name_no_ext}.csv")
                            self._save_dataframe_to_csv(csv_df, output_file)
                            
                            processed_count += 1
                            logger.info(f"CSV ì €ì¥ ì™„ë£Œ: {csv_df.shape[0]}í–‰, {csv_df.shape[1]}ì—´")
                            logger.info(f"ì €ì¥ ìœ„ì¹˜: {output_file}")
                        else:
                            failed_count += 1
                            logger.warning(f"ì‹¤íŒ¨: CSV ë³€í™˜ ì‹¤íŒ¨")
                    else:
                        failed_count += 1
                        logger.warning(f"ì‹¤íŒ¨: DataFrame ë³€í™˜ ì‹¤íŒ¨")
                        
                except Exception as e:
                    failed_count += 1
                    logger.error(f"ì˜¤ë¥˜ ë°œìƒ ({image_name}): {e}")
                    continue
            
            # ìµœì¢… ê²°ê³¼
            logger.info("Claude API ë³€í™˜ ì™„ë£Œ!")
            logger.info(f"ì„±ê³µ: {processed_count}ê°œ ì´ë¯¸ì§€")
            logger.info(f"ì‹¤íŒ¨: {failed_count}ê°œ ì´ë¯¸ì§€")
            logger.info(f"ì—…ìŠ¤ì¼€ì¼ë§ëœ ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {self.upscale_folder}")
            logger.info(f"ê²°ê³¼ CSV ì €ì¥ ìœ„ì¹˜: {case99_output_folder}")
            
            return processed_count > 0
            
        except Exception as e:
            logger.error(f"ì „ì²´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return False

    def convert_all_images(self):
        """ëª¨ë“  ì´ë¯¸ì§€ë¥¼ Claude APIë¡œ ë³€í™˜
        
        ì˜ë„: ì…ë ¥ í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ Claude APIë¡œ ì²˜ë¦¬í•˜ì—¬ CSV íŒŒì¼ ìƒì„±
        
        Returns:
            ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        image_files = get_image_files(self.input_folder, self.image_extensions)
        image_names = [os.path.splitext(os.path.basename(f))[0] for f in image_files]
        return self.convert_specific_images(image_names)

