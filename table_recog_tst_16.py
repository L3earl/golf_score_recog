"""
Table-Transformer Structure Recognition ê¸°ë°˜ í…Œì´ë¸” ê°ì§€ í…ŒìŠ¤íŠ¸
- data/raw_img í´ë”ì˜ ì´ë¯¸ì§€ë“¤ì„ ê°€ì ¸ì™€ì„œ
- microsoft/table-transformer-structure-recognition ëª¨ë¸ë¡œ í…Œì´ë¸” ê°ì§€ í›„
- ê°ì§€ëœ ì´ë¯¸ì§€ë¥¼ tst í´ë”ì— cropí•˜ì—¬ ì €ì¥
"""

import os
import cv2
import torch
import numpy as np
from PIL import Image
import glob
from transformers import TableTransformerForObjectDetection, DetrImageProcessor

def create_tst_folder():
    """tst í´ë” ìƒì„±"""
    tst_dir = "tst"
    os.makedirs(tst_dir, exist_ok=True)
    print(f"âœ… tst í´ë” ìƒì„±: {tst_dir}")
    return tst_dir

def get_image_files():
    """raw_img í´ë”ì˜ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    raw_img_dir = "data/raw_img"
    image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tiff']
    
    image_files = []
    for ext in image_extensions:
        pattern = os.path.join(raw_img_dir, ext)
        image_files.extend(glob.glob(pattern))
    
    print(f"ğŸ“ ë°œê²¬ëœ ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
    for img in image_files:
        print(f"   - {os.path.basename(img)}")
    
    return image_files

def load_table_transformer_model():
    """Table-Transformer Structure Recognition ëª¨ë¸ ë¡œë“œ"""
    print("ğŸ”„ Table-Transformer Structure Recognition ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    # Table-Transformer êµ¬ì¡° ì¸ì‹ ëª¨ë¸ ì‚¬ìš©
    model_name = "microsoft/table-transformer-structure-recognition"
    
    try:
        # ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ
        processor = DetrImageProcessor.from_pretrained(model_name)
        model = TableTransformerForObjectDetection.from_pretrained(model_name)
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
        return processor, model
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

def detect_tables(image_path, processor, model, output_dir):
    """ì´ë¯¸ì§€ì—ì„œ í…Œì´ë¸” ê°ì§€ í›„ cropí•˜ì—¬ ì €ì¥"""
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(image_path).convert("RGB")
        image_cv = cv2.imread(image_path)
        
        if image_cv is None:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return False
        
        print(f"   ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        inputs = processor(images=image, return_tensors="pt")
        
        # í…Œì´ë¸” ê°ì§€ ìˆ˜í–‰
        with torch.no_grad():
            outputs = model(**inputs)
        
        # ê²°ê³¼ í›„ì²˜ë¦¬
        target_sizes = torch.tensor([image.size[::-1]])  # (height, width)
        results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.7)[0]
        
        # ê°ì§€ëœ í…Œì´ë¸”ë“¤ ì²˜ë¦¬
        detections = []
        for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
            if score > 0.5:  # ë” ì—„ê²©í•œ confidence threshold
                x1, y1, x2, y2 = map(int, box)
                
                # í¬ê¸° í•„í„°ë§ ì¶”ê°€
                box_area = (x2 - x1) * (y2 - y1)
                image_area = image.size[0] * image.size[1]
                area_ratio = box_area / image_area
                
                # ì ì ˆí•œ í¬ê¸°ì˜ í…Œì´ë¸”ë§Œ ì„ íƒ (ì´ë¯¸ì§€ì˜ 5%~80% ë²”ìœ„)
                if 0.05 <= area_ratio <= 0.8:
                    detections.append({
                        'score': score.item(),
                        'box': box.tolist(),
                        'label': model.config.id2label[label.item()]
                    })
        
        print(f"   ğŸ” ê°ì§€ëœ í…Œì´ë¸”: {len(detections)}ê°œ")
        
        if not detections:
            print(f"   âš ï¸ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ê° ê°ì§€ëœ í…Œì´ë¸”ì— ëŒ€í•´ crop ë° ì €ì¥
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        success_count = 0
        
        for i, detection in enumerate(detections, 1):
            score = detection['score']
            box = detection['box']  # [x1, y1, x2, y2]
            
            # bounding box ì¢Œí‘œ ì¶”ì¶œ
            x1, y1, x2, y2 = map(int, box)
            
            # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬
            if x1 >= x2 or y1 >= y2:
                continue
            
            print(f"   í…Œì´ë¸” {i}: ì ìˆ˜ {score:.3f}, ì¢Œí‘œ ({x1}, {y1}, {x2}, {y2})")
            
            # ì´ë¯¸ì§€ crop
            cropped = image_cv[y1:y2, x1:x2]
            
            if cropped.size == 0:
                print(f"   âš ï¸ ì˜ëª»ëœ crop ì˜ì—­: {i}")
                continue
            
            # íŒŒì¼ëª… ìƒì„± ë° ì €ì¥
            output_filename = f"{base_name}_table{i}.png"
            output_path = os.path.join(output_dir, output_filename)
            
            cv2.imwrite(output_path, cropped)
            print(f"   âœ… ì €ì¥ ì™„ë£Œ: {output_filename}")
            success_count += 1
        
        return success_count > 0
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("Table-Transformer Structure Recognition ê¸°ë°˜ í…Œì´ë¸” ê°ì§€ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # tst í´ë” ìƒì„±
    tst_dir = create_tst_folder()
    
    # Table-Transformer ëª¨ë¸ ë¡œë“œ
    processor, model = load_table_transformer_model()
    
    if processor is None or model is None:
        print("âŒ ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_files = get_image_files()
    
    if not image_files:
        print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ í…Œì´ë¸” ê°ì§€ ìˆ˜í–‰
    success_count = 0
    total_count = len(image_files)
    
    print("\n" + "=" * 60)
    print("í…Œì´ë¸” ê°ì§€ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 60)
    
    for i, image_path in enumerate(image_files, 1):
        print(f"\n[{i}/{total_count}] ì²˜ë¦¬ ì¤‘: {os.path.basename(image_path)}")
        
        if detect_tables(image_path, processor, model, tst_dir):
            success_count += 1
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"ì´ ì²˜ë¦¬ íŒŒì¼: {total_count}")
    print(f"ì„±ê³µ: {success_count}")
    print(f"ì‹¤íŒ¨: {total_count - success_count}")
    print(f"ì„±ê³µë¥ : {(success_count / total_count * 100):.1f}%")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {tst_dir}")

if __name__ == "__main__":
    main()
