"""
LoFTR + OpenCV ê¸°ë°˜ íŠ¹ì§•ì  ë§¤ì¹­ í…ŒìŠ¤íŠ¸
- data/raw_img í´ë”ì˜ ì´ë¯¸ì§€ë“¤ì„ ê°€ì ¸ì™€ì„œ
- data/template_img/case3_01.pngì™€ LoFTR, OpenCV íŠ¹ì§•ì ìœ¼ë¡œ ë§¤ì¹­
- ë§¤ì¹­ëœ ì´ë¯¸ì§€ë¥¼ tst í´ë”ì— cropí•˜ì—¬ ì €ìž¥
"""

import os
import cv2
import torch
import numpy as np
from PIL import Image
import glob
import kornia as K
from kornia.feature import LoFTR

def create_tst_folder():
    """tst í´ë” ìƒì„±"""
    tst_dir = "tst"
    os.makedirs(tst_dir, exist_ok=True)
    print(f"âœ… tst í´ë” ìƒì„±: {tst_dir}")
    return tst_dir

def get_image_files():
    """raw_img í´ë”ì˜ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    raw_img_dir = "data/raw_img"
    image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.tiff']
    
    image_files = []
    for ext in image_extensions:
        pattern = os.path.join(raw_img_dir, ext)
        image_files.extend(glob.glob(pattern))
    
    print(f"ðŸ“ ë°œê²¬ëœ ì´ë¯¸ì§€ íŒŒì¼: {len(image_files)}ê°œ")
    for img in image_files:
        print(f"   - {os.path.basename(img)}")
    
    return image_files

def load_loftr_model():
    """LoFTR ëª¨ë¸ ë¡œë“œ"""
    print("ðŸ”„ LoFTR ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    try:
        # LoFTR ëª¨ë¸ ë¡œë“œ
        loftr = LoFTR(pretrained=True)
        print("âœ… LoFTR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return loftr
    except Exception as e:
        print(f"âŒ LoFTR ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def preprocess_image(image_path):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (í…ì„œ ë³€í™˜)"""
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        image = cv2.imread(image_path)
        if image is None:
            return None
        
        # BGR to RGB ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # PIL Imageë¡œ ë³€í™˜
        pil_image = Image.fromarray(image_rgb)
        
        # í…ì„œë¡œ ë³€í™˜ (H, W, C) -> (1, C, H, W)
        tensor_image = K.image_to_tensor(np.array(pil_image), keepdim=True).float() / 255.0
        
        return tensor_image, image
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None, None

def match_with_loftr(image_tensor, template_tensor):
    """LoFTRë¥¼ ì‚¬ìš©í•œ íŠ¹ì§•ì  ë§¤ì¹­"""
    try:
        loftr = load_loftr_model()
        if loftr is None:
            return None
        
        # LoFTR ë§¤ì¹­ ìˆ˜í–‰
        with torch.no_grad():
            input_dict = {
                "image0": template_tensor,
                "image1": image_tensor
            }
            match_dict = loftr(input_dict)
        
        # ë§¤ì¹­ ê²°ê³¼ ì¶”ì¶œ
        kpts0 = match_dict["keypoints0"].cpu().numpy()
        kpts1 = match_dict["keypoints1"].cpu().numpy()
        matches = match_dict["matches"].cpu().numpy()
        
        # ìœ íš¨í•œ ë§¤ì¹­ë§Œ í•„í„°ë§
        valid_matches = matches > -1
        if np.sum(valid_matches) < 10:  # ìµœì†Œ 10ê°œ ë§¤ì¹­ í•„ìš”
            return None
        
        matched_kpts0 = kpts0[valid_matches]
        matched_kpts1 = kpts1[matches[valid_matches]]
        
        return matched_kpts0, matched_kpts1
    except Exception as e:
        print(f"âŒ LoFTR ë§¤ì¹­ ì‹¤íŒ¨: {e}")
        return None

def match_with_opencv(image, template):
    """OpenCV SIFTë¥¼ ì‚¬ìš©í•œ íŠ¹ì§•ì  ë§¤ì¹­"""
    try:
        # SIFT íŠ¹ì§•ì  ê²€ì¶œê¸° ìƒì„±
        sift = cv2.SIFT_create()
        
        # íŠ¹ì§•ì ê³¼ ë””ìŠ¤í¬ë¦½í„° ì¶”ì¶œ
        kp1, des1 = sift.detectAndCompute(template, None)
        kp2, des2 = sift.detectAndCompute(image, None)
        
        if des1 is None or des2 is None:
            return None
        
        # FLANN ë§¤ì²˜ ì‚¬ìš©
        FLANN_INDEX_KDTREE = 1
        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
        search_params = dict(checks=50)
        flann = cv2.FlannBasedMatcher(index_params, search_params)
        
        # ë§¤ì¹­ ìˆ˜í–‰
        matches = flann.knnMatch(des1, des2, k=2)
        
        # Lowe's ratio test ì ìš©
        good_matches = []
        for match_pair in matches:
            if len(match_pair) == 2:
                m, n = match_pair
                if m.distance < 0.7 * n.distance:
                    good_matches.append(m)
        
        if len(good_matches) < 10:  # ìµœì†Œ 10ê°œ ë§¤ì¹­ í•„ìš”
            return None
        
        # ë§¤ì¹­ëœ íŠ¹ì§•ì  ì¢Œí‘œ ì¶”ì¶œ
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        
        return src_pts.reshape(-1, 2), dst_pts.reshape(-1, 2)
    except Exception as e:
        print(f"âŒ OpenCV ë§¤ì¹­ ì‹¤íŒ¨: {e}")
        return None

def find_homography_and_crop(kpts0, kpts1, template_image, source_image, output_dir, base_name, method_name):
    """í˜¸ëª¨ê·¸ëž˜í”¼ ê³„ì‚° í›„ crop"""
    try:
        if len(kpts0) < 4:
            return False
        
        # RANSACìœ¼ë¡œ í˜¸ëª¨ê·¸ëž˜í”¼ ê³„ì‚°
        H, mask = cv2.findHomography(kpts0, kpts1, cv2.RANSAC, 5.0)
        
        if H is None:
            return False
        
        # í…œí”Œë¦¿ ì´ë¯¸ì§€ í¬ê¸°
        h, w = template_image.shape[:2]
        
        # í…œí”Œë¦¿ì˜ ë„¤ ëª¨ì„œë¦¬ ì ë“¤
        template_corners = np.float32([[0, 0], [w, 0], [w, h], [0, h]]).reshape(-1, 1, 2)
        
        # í˜¸ëª¨ê·¸ëž˜í”¼ë¥¼ ì‚¬ìš©í•´ ì†ŒìŠ¤ ì´ë¯¸ì§€ì—ì„œ í•´ë‹¹ ì˜ì—­ ì°¾ê¸°
        source_corners = cv2.perspectiveTransform(template_corners, H)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
        x_coords = source_corners[:, 0, 0]
        y_coords = source_corners[:, 0, 1]
        
        x_min, x_max = int(np.min(x_coords)), int(np.max(x_coords))
        y_min, y_max = int(np.min(y_coords)), int(np.max(y_coords))
        
        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ ì œí•œ
        x_min = max(0, x_min)
        y_min = max(0, y_min)
        x_max = min(source_image.shape[1], x_max)
        y_max = min(source_image.shape[0], y_max)
        
        # crop ìˆ˜í–‰
        cropped = source_image[y_min:y_max, x_min:x_max]
        
        if cropped.size == 0:
            return False
        
        # ì €ìž¥
        output_filename = f"{base_name}_{method_name}_matched.png"
        output_path = os.path.join(output_dir, output_filename)
        cv2.imwrite(output_path, cropped)
        print(f"   âœ… ì €ìž¥ ì™„ë£Œ: {output_filename}")
        
        return True
    except Exception as e:
        print(f"âŒ í˜¸ëª¨ê·¸ëž˜í”¼ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return False

def match_and_crop(image_path, template_path, output_dir):
    """ì´ë¯¸ì§€ì™€ í…œí”Œë¦¿ ë§¤ì¹­ í›„ crop"""
    try:
        print(f"   ì²˜ë¦¬ ì¤‘: {os.path.basename(image_path)}")
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        image_tensor, image_cv = preprocess_image(image_path)
        template_tensor, template_cv = preprocess_image(template_path)
        
        if image_tensor is None or template_tensor is None:
            return False
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ (OpenCV ë§¤ì¹­ìš©)
        image_gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)
        template_gray = cv2.cvtColor(template_cv, cv2.COLOR_BGR2GRAY)
        
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        success = False
        
        # LoFTRë¡œ ë§¤ì¹­ ì‹œë„
        print("   ðŸ” LoFTR ë§¤ì¹­ ì‹œë„...")
        loftr_result = match_with_loftr(image_tensor, template_tensor)
        if loftr_result is not None:
            kpts0, kpts1 = loftr_result
            if find_homography_and_crop(kpts0, kpts1, template_cv, image_cv, output_dir, base_name, "loftr"):
                success = True
                print("   âœ… LoFTR ë§¤ì¹­ ì„±ê³µ")
        
        # OpenCV SIFTë¡œ ë§¤ì¹­ ì‹œë„
        print("   ðŸ” OpenCV SIFT ë§¤ì¹­ ì‹œë„...")
        opencv_result = match_with_opencv(image_gray, template_gray)
        if opencv_result is not None:
            kpts0, kpts1 = opencv_result
            if find_homography_and_crop(kpts0, kpts1, template_cv, image_cv, output_dir, base_name, "opencv"):
                success = True
                print("   âœ… OpenCV SIFT ë§¤ì¹­ ì„±ê³µ")
        
        return success
        
    except Exception as e:
        print(f"âŒ ë§¤ì¹­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("LoFTR + OpenCV SIFT ê¸°ë°˜ íŠ¹ì§•ì  ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ì‹œìž‘")
    print("=" * 60)
    
    # tst í´ë” ìƒì„±
    tst_dir = create_tst_folder()
    
    # í…œí”Œë¦¿ ê²½ë¡œ ì„¤ì •
    template_path = "data/template_img/case3_01.png"
    
    if not os.path.exists(template_path):
        print(f"âŒ í…œí”Œë¦¿ íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {template_path}")
        return
    
    print(f"ðŸŽ¯ ì‚¬ìš©í•  í…œí”Œë¦¿: {template_path}")
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_files = get_image_files()
    
    if not image_files:
        print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë§¤ì¹­ ìˆ˜í–‰
    success_count = 0
    total_count = len(image_files)
    
    print("\n" + "=" * 60)
    print("íŠ¹ì§•ì  ë§¤ì¹­ ì²˜ë¦¬ ì‹œìž‘")
    print("=" * 60)
    
    for i, image_path in enumerate(image_files, 1):
        print(f"\n[{i}/{total_count}] ì²˜ë¦¬ ì¤‘: {os.path.basename(image_path)}")
        
        if match_and_crop(image_path, template_path, tst_dir):
            success_count += 1
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"ì´ ì²˜ë¦¬ íŒŒì¼: {total_count}")
    print(f"ì„±ê³µ: {success_count}")
    print(f"ì‹¤íŒ¨: {total_count - success_count}")
    print(f"ì„±ê³µë¥ : {(success_count / total_count * 100):.1f}%")
    print(f"ê²°ê³¼ ì €ìž¥ ìœ„ì¹˜: {tst_dir}")

if __name__ == "__main__":
    main()
