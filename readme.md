## 전체 프로세스 흐름
시스템은 아래와 같은 순서로 작동하며, TrOCR(로컬 OCR) 파이프라인과 Claude(LLM) 파이프라인 두 가지를 모두 고려하고 있습니다.

[이미지 입력]
    |
    ▼
[1. 전처리] : 이미지 자르기(crop) → 얼룩 제거(clean)
    |
    ▼
[2. OCR 변환] : 전처리된 이미지를 TrOCR 모델로 텍스트 변환
    |
    ▼
[3. 후처리] : 빈 행 제거, Sum 계산해서 넣어줌 (변환 과정에서 sum값 중에 100이 넘는 것들은 인식을 못하는 경우가 있음)
    |
    ▼
[4. 데이터 검증 (1차)] : 숫자 인식 못한 경우, 전체 타수와 total의 계산이 불일치하는 경우, 모든 숫자를 인식 못해서 플레이어가 없는 경우 등 예외 케이스 처리
    |
    ▼
[5. Claude 변환] : 예외 파일들만 원본 이미지를 Claude API로 CSV 형식으로 재변환
    |
    ▼
[6. 최종 결과] : 처리 완료 및 결과 요약
<hr/>

## 실행을 위해 해야 하는 것
- 맨 위 폴더에 .env 파일 만들고 ANTHROPIC_API_KEY = API_KEY 넣어주셔야 함

- requirement에 있는 라이브러리들 설치가 필요함. 특히 머신러닝 모델을 쓰려면 torch 라이브러리들이 필요합니다. [제가 한 방법](https://earls.notion.site/119abb83012043159fee15b3c73235cc?pvs=74) 들어가셔서 환경설정> 윈도우 자체에 CUDA 설치 > 1번 부터 참고하시면 됩니다 (window일시)

    

## 테스트 남은 이슈
- 현황: '이글' 표시와 같은 얼룩이 있는 숫자를 인식시키기 위해, 검은색 외의 모든 색상을 제거하는 전처리 로직이 적용되어 있습니다.
 
필요 작업: 현재 -1 케이스만 테스트된 상태입니다. 버디(새), 더블보기(네모) 등 다른 종류의 아이콘이나 얼룩이 있는 경우에도 이 로직이 유효한지 다양한 케이스에 대한 테스트가 필요합니다.

필요 작업: -1 외에 -2, -3, -4 등 다른 음수 값도 정확히 인식하는지 테스트가 필요합니다.

필요 작업: Claude API의 CSV 형식 응답이 다양한 스코어카드 레이아웃에서 일관되게 작동하는지 검증이 필요합니다.
 

## 주요 이슈
- GPU가 필요합니다. CPU로는 속도가 나지 않음

현재 매 처리마다 모델을 GPU 메모리에 로드하고 있습니다. 이 시간이 전체 시간의 50% 정도를 차지합니다. 실제 서비스에서는 모델을 한 번만 GPU 메모리에 올린 후, 여러 요청을 메모리 상에서 계속 처리하도록 아키텍처를 변경해야 합니다.

- TrOCR 모델 한계점 : microsoft/trocr-large-printed 모델은 숫자 인식률이 높지만, 세 자릿수 숫자('100' 이상)를 인식하지 못하는 문제가 있습니다.

임시 해결책: 세 자릿수는 주로 'SUM' 열에만 등장하므로, 현재는 SUM 열의 데이터를 사용하지 않는 방식으로 우회하고 있습니다.

- LLM 프롬프트 최적화

필요 작업: 스코어카드의 양식(앱 종류, 레이아웃 등)이 다양하므로, 현재 프롬프트가 특정 케이스에서는 최적이 아닐 수 있습니다. 여러 종류의 이미지에 일관적으로 높은 성능을 내는 범용 프롬프트를 찾는 연구 및 테스트가 필요합니다.

- 모든 프로세스를 통과하지 못 한 경우, 어떻게 할지 얘기해봐야 함

- debug위한 코드들 지워야 함




# 251014
지금 코드는 GPU한개의 처리 능력을 다 쓰는거 같은데? 여러개 동시에 들어오면 훨씬 느려짐. 실서비스를 위해 속도 늘리려면 어떻게 하나
1. 좋은 GPU를 여러장 사서 분산처리 한다
2. 실시간으로 서비스를 제공하지 않는다
3. 클로드 API 2번째 버전 (가격 개당 15원 나오는 거)를 프롬프트 튜닝 잘 해서 쓴다
4. 딥러닝 모델이 아닌 아주 옛날 CV 방식을 사용한다 (아마 빠를 듯? )- 다만 2자리수, 음수는 인식 못하는 문제 풀어야 함
4-1. 좌표에 맞춰서 2자리수, 음수를 분리하여 1자리수 양수로 만든 후에 적용 (초 하드코딩)
4-2. 2자리수는 포기하고, 음수만 학습시킨 버전을 다시 만듦 (2자리수는 중요도가 높진 않은데다가, 학습을 위해서는 10~99?까지 가능한 수의 디자인이 다 있어야 함)
5. 지금 모델보다 빠르고, 정확도는 100% 나오는 모델을 노가다로 찾는다 (결과가 나올 수 있을지 없을지 명확하지 않음)


# 이슈
- 속도를 조금이라도 증가시키려면 중요도가 낮은 total, sum 빼버리기

할일
케이스3 box 좌표 알아내서 crop 하기 -> 좌표 따기 -> crop & clean 잘 되나 확인
케이스2번은 crop &clean 잘되나 확인
최적화는 일단 나중에 생각하고, main.py돌리면 3개 모델 다 돌아가게 해서 아래 구글sheet 결과지에 정보 올리기,CSV로 만들어서 주기
구글 sheet 에 각 case별로 정답지 만들기
구글 sheet 연결해서, main.py 돌릴때마다 결과지에 정보 올리게 하고, 정답지랑 비교해서 자동으로 정확도 나오게 하기 (매번 눈으로 보기 빡세니까)
3개 케이스에서 postprocess돌려서 하나라도 통과하면 cluade를 호출할 필요 없음


config에 case3이 추가되야 작업한다고? 이건 수정 필요



할일1017
클로드 프롬프트를 조절해서 원하는 데이터만 추출하는게 어려움 (프롬프트를 아무리 변경해도 결과물이 잘 변하지 않고 있음)
스코어 카드는 너무 여러 형식임

방법1
이미지+프롬프트로 고급 모델을 써서 데이터를 추출
위 결과물 + 프롬프트로, 작은 모델을 써서 데이터 필터링과 형태를 맞춤


방법2
초 하드코인
구글에 스코어 카드라고 쳐서 나오는 모든 경우의 수에 맞춰 결과물을 하나씩정제하도록 함 (찝찝한 방법임)

 _parse_csv_to_dataframe에서 CSV 문자열을 pandas DataFrame으로 파싱 한 이후에 해당 데이터프레임을 아래와 같이 조작할꺼야
- 1열 데이터가 모두 문자거나 비어있다면, 1열 삭제
- 1열이 숫자이면서, 10열의 데이터가 2자리수 숫자라면 -> 해당 열은 뒤에서 3번쨰로 옮김
- 1번 데이터가 1이고, 숫자가 1씩 증가하는게 5번 이상 반복되는 행은 삭제
- 

행보다 열이 길면 t
100이상의 숫자들이 대다수면 행 삭제
1열 인덱스를 기준으로 특정 단어들은 따로 뺴둠 (par -> 파 정보, Hole -> 지울 것, 등등)
